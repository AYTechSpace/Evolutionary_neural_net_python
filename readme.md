v2.1.1

Initially as part of CS50p I produced a program where a neural network is trained add two binary numbers. Starting from a single perceptron node, to generating a population of networks with a variable number of hidden layers.

As of right now, and as of how this projet will be handed in, it will work by reproducing copies of the best performing networks with slights mutations

There are potential plans in the future to change this elite-dreg system into a royalty, upper, and lower classification system with different ways of producing the next generation to better prevent getting stuck in local minima or losing needed variation

However, if this will be done in python using different libraries, or another language is yet to be determined




# Legacy comments for practise

# This is a comment

# git branch -d <branch_name>: deletes branch

# git branch <branch_name>: changes branch

# git checkout <branch_name>: also changes branch?

# git checkout -b <new_branch_name>: send you to new branch

# git commit -m <message>: adds branch to commit area so that it can be pushed to origin later

# git push -u origin master: update origin with master (-u means it'll remember to send to origin from master so we can just write git push now)

# git pull origin master: updates master using origin